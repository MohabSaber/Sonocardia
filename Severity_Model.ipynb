{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCYDf83-r8Dx",
        "outputId": "489ed710-bc35-4652-9594-9cab716e4918"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Patient ID', 'Locations', 'Age', 'Sex', 'Height', 'Weight',\n",
            "       'Pregnancy status', 'Murmur', 'Murmur locations',\n",
            "       'Most audible location', 'Systolic murmur timing',\n",
            "       'Systolic murmur shape', 'Systolic murmur grading',\n",
            "       'Systolic murmur pitch', 'Systolic murmur quality',\n",
            "       'Diastolic murmur timing', 'Diastolic murmur shape',\n",
            "       'Diastolic murmur grading', 'Diastolic murmur pitch',\n",
            "       'Diastolic murmur quality', 'Campaign', 'Additional ID',\n",
            "       'valid_file_paths', 'features'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def load_and_preprocess_audio(file_path, sr=22050, n_mfcc=13, max_length=200):\n",
        "    y, sr = librosa.load(file_path, sr=sr)\n",
        "    y = librosa.util.normalize(y)\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "    mfccs = mfccs.T  # Transpose to shape (time_steps, n_mfcc)\n",
        "    mfccs = pad_sequences([mfccs], maxlen=max_length, dtype='float32', padding='post', truncating='post')[0]\n",
        "    return mfccs\n",
        "\n",
        "def process_dataset(audio_folder, csv_file, max_length=200):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    X, y = [], []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        patient_id = str(row['Patient ID'])\n",
        "        murmur = row['Murmur']\n",
        "        murmur_loc = row['Murmur locations']\n",
        "        systolic_timing = row['Systolic murmur timing']\n",
        "        diastolic_timing = row['Diastolic murmur timing']\n",
        "\n",
        "        patient_folder = os.path.join(audio_folder, patient_id)\n",
        "        if os.path.exists(patient_folder):\n",
        "            for file in os.listdir(patient_folder):\n",
        "                if file.endswith(('.wav', '.mp3')):\n",
        "                    file_path = os.path.join(patient_folder, file)\n",
        "                    mfccs = load_and_preprocess_audio(file_path, max_length=max_length)\n",
        "                    X.append(mfccs)\n",
        "                    y.append([murmur, murmur_loc, systolic_timing, diastolic_timing])\n",
        "\n",
        "    return np.array(X), y\n",
        "\n",
        "def build_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Paths (Edit these based on your dataset)\n",
        "audio_folder = \"/content/Organized_Patients\"\n",
        "csv_file = \"/content/drive/MyDrive/training_data.csv\"\n",
        "\n",
        "# Load dataset\n",
        "X, y = process_dataset(audio_folder, csv_file)\n",
        "X = np.expand_dims(X, axis=-1)  # Add channel dimension\n",
        "\n",
        "# Encode labels\n",
        "unique_labels = list(set([tuple(label) for label in y]))\n",
        "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "y_encoded = np.array([label_to_index[tuple(label)] for label in y])\n",
        "y_categorical = to_categorical(y_encoded, num_classes=len(unique_labels))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and train model\n",
        "input_shape = X_train.shape[1:]\n",
        "num_classes = len(unique_labels)\n",
        "model = build_model(input_shape, num_classes)\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiyUAsc4In6J",
        "outputId": "3fc59c82-b6ad-4b64-df88-44f71c0a06dc"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5879 - loss: 18.5697 - val_accuracy: 0.7299 - val_loss: 1.5294\n",
            "Epoch 2/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.7583 - loss: 1.5257 - val_accuracy: 0.7299 - val_loss: 1.6394\n",
            "Epoch 3/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.7521 - loss: 1.5428 - val_accuracy: 0.7299 - val_loss: 1.3674\n",
            "Epoch 4/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.7467 - loss: 1.4176 - val_accuracy: 0.7299 - val_loss: 1.3350\n",
            "Epoch 5/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.7603 - loss: 1.2844 - val_accuracy: 0.7299 - val_loss: 1.3530\n",
            "Epoch 6/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.7636 - loss: 1.2857 - val_accuracy: 0.7299 - val_loss: 1.4250\n",
            "Epoch 7/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.7804 - loss: 1.1602 - val_accuracy: 0.7314 - val_loss: 1.4013\n",
            "Epoch 8/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 74ms/step - accuracy: 0.7645 - loss: 1.2003 - val_accuracy: 0.7330 - val_loss: 1.5198\n",
            "Epoch 9/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - accuracy: 0.7632 - loss: 1.1816 - val_accuracy: 0.7299 - val_loss: 1.5744\n",
            "Epoch 10/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.7757 - loss: 1.1101 - val_accuracy: 0.7346 - val_loss: 1.4614\n",
            "Epoch 11/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7726 - loss: 1.0712 - val_accuracy: 0.7346 - val_loss: 1.4179\n",
            "Epoch 12/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.7773 - loss: 1.0743 - val_accuracy: 0.7346 - val_loss: 1.4652\n",
            "Epoch 13/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.7684 - loss: 1.0387 - val_accuracy: 0.7362 - val_loss: 1.3885\n",
            "Epoch 14/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.7713 - loss: 1.0263 - val_accuracy: 0.7378 - val_loss: 1.3946\n",
            "Epoch 15/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.7586 - loss: 1.1449 - val_accuracy: 0.7283 - val_loss: 1.5405\n",
            "Epoch 16/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.7771 - loss: 0.9111 - val_accuracy: 0.7046 - val_loss: 1.6048\n",
            "Epoch 17/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.7899 - loss: 0.9016 - val_accuracy: 0.7299 - val_loss: 1.5843\n",
            "Epoch 18/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.7887 - loss: 0.9021 - val_accuracy: 0.7251 - val_loss: 1.5995\n",
            "Epoch 19/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.7914 - loss: 0.8198 - val_accuracy: 0.7378 - val_loss: 1.6225\n",
            "Epoch 20/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 95ms/step - accuracy: 0.7996 - loss: 0.7383 - val_accuracy: 0.7251 - val_loss: 1.6227\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7589 - loss: 1.4172\n",
            "Test Accuracy: 72.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def classify_heart_sound(model, file_path, max_length=200, sr=22050, n_mfcc=13):\n",
        "    # Load and preprocess the input audio\n",
        "    y, sr = librosa.load(file_path, sr=sr)\n",
        "    y = librosa.util.normalize(y)\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc).T\n",
        "\n",
        "    # Pad or truncate to ensure consistent shape\n",
        "    mfccs = pad_sequences([mfccs], maxlen=max_length, dtype='float32', padding='post', truncating='post')[0]\n",
        "    mfccs = np.expand_dims(mfccs, axis=-1)  # Add channel dimension\n",
        "    mfccs = np.expand_dims(mfccs, axis=0)   # Add batch dimension\n",
        "\n",
        "    # Predict\n",
        "    predictions = model.predict(mfccs)\n",
        "    predicted_label_index = np.argmax(predictions)\n",
        "\n",
        "    # Decode label\n",
        "    index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
        "    predicted_label = index_to_label[predicted_label_index]\n",
        "\n",
        "    print(f\"Predicted Classification: {predicted_label}\")\n",
        "    return predicted_label\n",
        "\n",
        "# Example usage (edit the file path accordingly):\n",
        "file_path = \"/content/drive/MyDrive/murmur__197_1308141235553_C.wav\"\n",
        "predicted_class = classify_heart_sound(model, file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSWQLlMDIn3o",
        "outputId": "07aa584f-de55-4f18-d968-976715e64e42"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Predicted Classification: ('Present', 'AV+MV+PV+TV', 'Holosystolic', nan)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqidUoXCIn1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PPzvbltIInzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the directory containing the audio files and the target directory\n",
        "source_directory = \"/content/drive/MyDrive/Severity_training_data\"  # Replace with the actual path to your audio files\n",
        "target_directory = \"Organized_Patients\"\n",
        "\n",
        "# Ensure the target directory exists\n",
        "os.makedirs(target_directory, exist_ok=True)\n",
        "\n",
        "# Iterate through all files in the source directory\n",
        "for filename in os.listdir(source_directory):\n",
        "    if filename.endswith(\".wav\"):  # Process only .wav files\n",
        "        # Extract the patient ID and location from the filename\n",
        "        patient_id, location = filename.split(\"_\")[0], filename.split(\"_\")[-1]\n",
        "        location = location.split(\".\")[0]\n",
        "\n",
        "        # Create a directory for the patient if it doesn't exist\n",
        "        patient_folder = os.path.join(target_directory, patient_id)\n",
        "        os.makedirs(patient_folder, exist_ok=True)\n",
        "\n",
        "        # Move or copy the audio file to the patient's folder\n",
        "        source_file_path = os.path.join(source_directory, filename)\n",
        "        target_file_path = os.path.join(patient_folder, filename)\n",
        "        shutil.move(source_file_path, target_file_path)  # Use shutil.copy if you want to copy instead\n",
        "\n",
        "print(\"Audio files have been organized successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRc0eOGtvRnk",
        "outputId": "e841abcb-5d8c-414d-cb66-a05c41d70c92"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio files have been organized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7CcCtjkH6F1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qt7Q0ayJB63n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the directory containing the audio files and the target directory\n",
        "source_directory = \"/content/drive/MyDrive/Severity_training_data\"  # Replace with the actual path to your audio files\n",
        "target_directory = \"Organized_Patients22222222222\"\n",
        "\n",
        "# Ensure the target directory exists\n",
        "os.makedirs(target_directory, exist_ok=True)\n",
        "\n",
        "# Define the possible labels\n",
        "labels = ['_AV', '_TV', '_PV', '_MV']\n",
        "\n",
        "# Create folders for each label within the target directory\n",
        "for label in labels:\n",
        "    label_folder = os.path.join(target_directory, label)\n",
        "    os.makedirs(label_folder, exist_ok=True)\n",
        "\n",
        "# Iterate through all files in the source directory\n",
        "for filename in os.listdir(source_directory):\n",
        "    if filename.endswith(\".wav\"):  # Process only .wav files\n",
        "        # Extract the patient ID and location from the filename\n",
        "        patient_id, location = filename.split(\"_\")[0], filename.split(\"_\")[-1]\n",
        "        location = location.split(\".\")[0]\n",
        "\n",
        "        # Create a dictionary to store which labels are present for this patient\n",
        "        patient_labels = {label: False for label in labels}\n",
        "\n",
        "        # Check if each label is present in the filename\n",
        "        for label in labels:\n",
        "            if label in filename:\n",
        "                patient_labels[label] = True\n",
        "\n",
        "        # Now move the file into the corresponding label folder for the patient\n",
        "        for label, is_present in patient_labels.items():\n",
        "            if is_present:  # If the label is present in the filename\n",
        "                # Create a directory for the patient within the label folder if it doesn't exist\n",
        "                patient_folder = os.path.join(target_directory, label, patient_id)\n",
        "                os.makedirs(patient_folder, exist_ok=True)\n",
        "\n",
        "                # Move the audio file to the appropriate folder\n",
        "                source_file_path = os.path.join(source_directory, filename)\n",
        "                target_file_path = os.path.join(patient_folder, filename)\n",
        "                shutil.move(source_file_path, target_file_path)  # Use shutil.copy to copy instead of move\n",
        "\n",
        "print(\"Audio files have been organized successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQZrJ_pvB6wY",
        "outputId": "07bc053a-9ce9-4e51-a8ee-39a7cfb4ad18"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio files have been organized successfully.\n"
          ]
        }
      ]
    }
  ]
}